{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_Part 3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo3QklZw2sTY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing the necessary lib\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import LSTM, BatchNormalization,concatenate,Flatten,Embedding,Dense,Dropout,MaxPooling2D,CuDNNLSTM,SpatialDropout1D\n",
        "from keras.models import Sequential\n",
        "from keras import Model,Input\n",
        "from keras.layers.convolutional import Conv2D,Conv1D\n",
        "import keras.backend as k\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import tensorflow as tf\n",
        "from keras.initializers import he_normal\n",
        "from keras.callbacks import Callback, EarlyStopping\n",
        "from time import time\n",
        "from tensorflow.python.keras.callbacks import TensorBoard,ModelCheckpoint\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import keras\n",
        "from keras.regularizers import l2\n",
        "import pickle\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UV-9WLdp3EOz",
        "colab_type": "code",
        "outputId": "6340c408-c32e-48cb-838c-baa7dd8b7e25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX2xLC8V3K-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Applied ML assignments/preprocessed_data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fQ8l6gq3Uxw",
        "colab_type": "code",
        "outputId": "a0a5f7e4-8f6f-4280-c6fb-3993adabe093",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "resource_data = pd.read_csv('/content/drive/My Drive/LSTM Assignment/resources.csv')\n",
        "resource_data.columns\n",
        "project_data = pd.read_csv('/content/drive/My Drive/LSTM Assignment/train_data.csv')\n",
        "project_data.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'id', 'teacher_id', 'teacher_prefix', 'school_state',\n",
              "       'project_submitted_datetime', 'project_grade_category',\n",
              "       'project_subject_categories', 'project_subject_subcategories',\n",
              "       'project_title', 'project_essay_1', 'project_essay_2',\n",
              "       'project_essay_3', 'project_essay_4', 'project_resource_summary',\n",
              "       'teacher_number_of_previously_posted_projects', 'project_is_approved'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coNLgbmm3YLM",
        "colab_type": "code",
        "outputId": "09b7c54a-356a-42ca-c982-660fdc2a614a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "price_data = resource_data.groupby('id').agg({'price':'sum', 'quantity':'sum'}).reset_index()\n",
        "price_data.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>price</th>\n",
              "      <th>quantity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>p000001</td>\n",
              "      <td>459.56</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>p000002</td>\n",
              "      <td>515.89</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id   price  quantity\n",
              "0  p000001  459.56         7\n",
              "1  p000002  515.89        21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZECVqGwz3bCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "project_data = pd.merge(project_data, price_data, on='id', how='left')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKngU8Rx3eDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['quantity'] = project_data['quantity']\n",
        "#df1['columename']= df2['existing_colume_name']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJq2nEyM3peu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=df['project_is_approved']\n",
        "df.drop(['project_is_approved'],axis=1, inplace=True)\n",
        "x=df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSOXW9L13wFe",
        "colab_type": "code",
        "outputId": "0b903791-7739-4264-84f4-9f48dba4d98f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "#Splitting into train and test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)\n",
        "#Splitting train data into train and cv(60:20)\n",
        "X_tr, X_cv, y_tr, y_cv = train_test_split(X_train, y_train, test_size=0.2)\n",
        "print(X_tr.shape, y_tr.shape)\n",
        "print(X_cv.shape, y_cv.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(87398, 9) (87398,)\n",
            "(21850, 9) (21850,)\n",
            "(69918, 9) (69918,)\n",
            "(17480, 9) (17480,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAPma3xu39cb",
        "colab_type": "code",
        "outputId": "e2fdbad1-5fc4-4dfa-a1fc-6dd01c58d3b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "#Converting categorical features to One hot encoded features\n",
        "#clean_categories\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(X_tr['clean_categories'].values)\n",
        "categories_one_hot_train = vectorizer.transform(X_tr['clean_categories'].values)\n",
        "categories_one_hot_cv = vectorizer.transform(X_cv['clean_categories'].values)\n",
        "categories_one_hot_test = vectorizer.transform(X_test['clean_categories'].values)\n",
        "print(categories_one_hot_train.shape)\n",
        "print(categories_one_hot_test.shape)\n",
        "print(categories_one_hot_cv.shape)\n",
        "\n",
        "#clean_subcategories\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(X_tr['clean_subcategories'].values)\n",
        "subcategories_one_hot_train = vectorizer.transform(X_tr['clean_subcategories'].values)\n",
        "subcategories_one_hot_cv = vectorizer.transform(X_cv['clean_subcategories'].values)\n",
        "subcategories_one_hot_test = vectorizer.transform(X_test['clean_subcategories'].values)\n",
        "print(subcategories_one_hot_train.shape)\n",
        "print(subcategories_one_hot_test.shape)\n",
        "print(subcategories_one_hot_cv.shape)\n",
        "\n",
        "#school_state\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(X_tr['school_state'].values)\n",
        "schoolstate_one_hot_train = vectorizer.transform(X_tr['school_state'].values)\n",
        "schoolstate_one_hot_cv = vectorizer.transform(X_cv['school_state'].values)\n",
        "schoolstate_one_hot_test = vectorizer.transform(X_test['school_state'].values)\n",
        "print(schoolstate_one_hot_train.shape)\n",
        "print(schoolstate_one_hot_test.shape)\n",
        "print(schoolstate_one_hot_cv.shape)\n",
        "\n",
        "#project_grade_category\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(X_tr['project_grade_category'].values)\n",
        "project_grade_category_one_hot_train = vectorizer.transform(X_tr['project_grade_category'].values)\n",
        "project_grade_category_one_hot_cv = vectorizer.transform(X_cv['project_grade_category'].values)\n",
        "project_grade_category_one_hot_test = vectorizer.transform(X_test['project_grade_category'].values)\n",
        "print(project_grade_category_one_hot_train.shape)\n",
        "print(project_grade_category_one_hot_test.shape)\n",
        "print(project_grade_category_one_hot_cv.shape)\n",
        "\n",
        "\n",
        "\n",
        "#teacher_prefix\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(X_tr['teacher_prefix'].values)\n",
        "teacherprefix_ohe_train = vectorizer.transform(X_tr['teacher_prefix'].values)\n",
        "teacherprefix_ohe_cv = vectorizer.transform(X_cv['teacher_prefix'].values)\n",
        "teacherprefix_ohe_test = vectorizer.transform(X_test['teacher_prefix'].values)\n",
        "print(teacherprefix_ohe_cv.shape)\n",
        "print(teacherprefix_ohe_train.shape)\n",
        "print(teacherprefix_ohe_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(69918, 9)\n",
            "(21850, 9)\n",
            "(17480, 9)\n",
            "(69918, 30)\n",
            "(21850, 30)\n",
            "(17480, 30)\n",
            "(69918, 51)\n",
            "(21850, 51)\n",
            "(17480, 51)\n",
            "(69918, 4)\n",
            "(21850, 4)\n",
            "(17480, 4)\n",
            "(17480, 5)\n",
            "(69918, 5)\n",
            "(21850, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bovbT3kC54sJ",
        "colab_type": "code",
        "outputId": "e7ea6e03-f1eb-45d0-bdc2-d58a37ce2805",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "source": [
        "from sklearn.preprocessing import Normalizer\n",
        "normalizer = Normalizer()\n",
        "normalizer.fit(X_tr['price'].values.reshape(-1,1))\n",
        "\n",
        "x_train_price_norm = normalizer.transform(X_tr['price'].values.reshape(-1,1))\n",
        "x_cv_price_norm = normalizer.transform(X_cv['price'].values.reshape(-1,1))\n",
        "x_test_price_norm = normalizer.transform(X_test['price'].values.reshape(-1,1))\n",
        "\n",
        "print(\"After normalizing price\")\n",
        "print(x_train_price_norm.shape, y_tr.shape)\n",
        "print(x_cv_price_norm.shape, y_cv.shape)\n",
        "print(x_test_price_norm.shape, y_test.shape)\n",
        "\n",
        "print(\"========================================================\")\n",
        "\n",
        "normalizer = Normalizer()\n",
        "normalizer.fit(X_tr['quantity'].values.reshape(-1,1))\n",
        "\n",
        "x_train_qty_norm = normalizer.transform(X_tr['quantity'].values.reshape(-1,1))\n",
        "x_cv_qty_norm = normalizer.transform(X_cv['quantity'].values.reshape(-1,1))\n",
        "x_test_qty_norm = normalizer.transform(X_test['quantity'].values.reshape(-1,1))\n",
        "print(\"After normalizing the quantity\")\n",
        "print(x_train_qty_norm.shape, y_tr.shape)\n",
        "print(x_cv_qty_norm.shape, y_cv.shape)\n",
        "print(x_test_qty_norm.shape, y_test.shape)\n",
        "print(\"========================================================\")\n",
        "\n",
        "normalizer = Normalizer()\n",
        "normalizer.fit(X_tr['teacher_number_of_previously_posted_projects'].values.reshape(-1,1))\n",
        "\n",
        "x_train_tpp_norm = normalizer.transform(X_tr['teacher_number_of_previously_posted_projects'].values.reshape(-1,1))\n",
        "x_cv_tpp_norm = normalizer.transform(X_cv['teacher_number_of_previously_posted_projects'].values.reshape(-1,1))\n",
        "x_test_tpp_norm = normalizer.transform(X_test['teacher_number_of_previously_posted_projects'].values.reshape(-1,1))\n",
        "print(\"After normalizing the teacher_number_of_previously_posted_projects\")\n",
        "print(x_train_qty_norm.shape, y_tr.shape)\n",
        "print(x_cv_qty_norm.shape, y_cv.shape)\n",
        "print(x_test_qty_norm.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After normalizing price\n",
            "(69918, 1) (69918,)\n",
            "(17480, 1) (17480,)\n",
            "(21850, 1) (21850,)\n",
            "========================================================\n",
            "After normalizing the quantity\n",
            "(69918, 1) (69918,)\n",
            "(17480, 1) (17480,)\n",
            "(21850, 1) (21850,)\n",
            "========================================================\n",
            "After normalizing the teacher_number_of_previously_posted_projects\n",
            "(69918, 1) (69918,)\n",
            "(17480, 1) (17480,)\n",
            "(21850, 1) (21850,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3IKZoxD5H01",
        "colab_type": "code",
        "outputId": "e8c60b04-c020-497c-a0a5-15cccb3ec12b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "#print(schoolstate_one_hot_train.shape)\n",
        "from scipy import sparse\n",
        "from numpy import hstack\n",
        "x_tr_rem = sparse.hstack((schoolstate_one_hot_train, teacherprefix_ohe_train, project_grade_category_one_hot_train,subcategories_one_hot_train,categories_one_hot_train, x_train_price_norm,x_train_qty_norm,x_train_tpp_norm)).todense()\n",
        "x_cv_rem = sparse.hstack(( schoolstate_one_hot_cv, teacherprefix_ohe_cv, project_grade_category_one_hot_cv,subcategories_one_hot_cv,categories_one_hot_cv, x_cv_price_norm,x_cv_qty_norm,x_cv_tpp_norm)).todense()\n",
        "x_te_rem = sparse.hstack((schoolstate_one_hot_test, teacherprefix_ohe_test, project_grade_category_one_hot_test,subcategories_one_hot_test,categories_one_hot_test, x_test_price_norm,x_test_qty_norm,x_test_tpp_norm)).todense()\n",
        "print(\"Final Data matrix\")\n",
        "print(x_tr_rem.shape, y_tr.shape)\n",
        "print(x_cv_rem.shape, y_cv.shape)\n",
        "print(x_te_rem.shape, y_test.shape)\n",
        "print(\"=\"*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final Data matrix\n",
            "(69918, 102) (69918,)\n",
            "(17480, 102) (17480,)\n",
            "(21850, 102) (21850,)\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nm3ld-KFf-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "mms = StandardScaler().fit(x_tr_rem)\n",
        "x_tr_rem_norm = mms.transform(x_tr_rem)\n",
        "x_cv_rem_norm = mms.transform(x_cv_rem)\n",
        "x_te_rem_norm = mms.transform(x_te_rem)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQlWMLwNFp7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_tr_rem_reshape = np.array(x_tr_rem).reshape(69918,102,1)\n",
        "x_cv_rem_reshape = np.array(x_cv_rem).reshape(17480, 102,1)\n",
        "x_test_rem_reshape = np.array(x_te_rem).reshape(21850, 102,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDz3Xo6_FuFv",
        "colab_type": "code",
        "outputId": "6feeced3-6f69-4f2e-8a5f-3cd688faaa2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "max_length=400\n",
        "#https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
        "def padded(encoded_docs):  \n",
        "  max_length = 400\n",
        "  padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "  return padded_docs\n",
        "\n",
        "\n",
        "#https://stackoverflow.com/posts/51956230/revisions\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(X_tr['essay'].values)\n",
        "vocab_size = len(t.word_index) + 1\n",
        "# integer encode the documents\n",
        "encoded_docs = t.texts_to_sequences(X_tr['essay'].values)\n",
        "essay_padded_train = padded(encoded_docs)\n",
        "\n",
        "\n",
        "# integer encode the documents\n",
        "encoded_docs = t.texts_to_sequences(X_cv['essay'].values)\n",
        "essay_padded_cv = padded(encoded_docs)\n",
        "\n",
        "\n",
        "encoded_docs = t.texts_to_sequences(X_test['essay'].values)\n",
        "essay_padded_test = padded(encoded_docs)\n",
        "\n",
        "\n",
        "\n",
        "print(\"encoded train data shape\",essay_padded_train.shape)\n",
        "print(\"encoded cv data shape\",essay_padded_cv.shape)\n",
        "print(\"encoded cv data shape\",essay_padded_test.shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoded train data shape (69918, 400)\n",
            "encoded cv data shape (17480, 400)\n",
            "encoded cv data shape (21850, 400)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFFxPXKnGHkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings_index = dict()\n",
        "f = open('/content/drive/My Drive/Applied ML assignments/glove.6B.300d.txt')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LgELp0CGqh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 300))\n",
        "for word, i in t.word_index.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmMRB0XwG6DB",
        "colab_type": "code",
        "outputId": "3b69b99d-7815-4c59-95b6-7344309473ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"embedding matrix shape\",embedding_matrix.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "embedding matrix shape (47467, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5fjXcXFG8wb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "y_binary_train = to_categorical(y_tr)\n",
        "y_binary_cv = to_categorical(y_cv)\n",
        "y_binary_test = to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdX6nyoVHMYy",
        "colab_type": "code",
        "outputId": "f20d55d1-efeb-4544-fe71-d3ae610314a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "import keras\n",
        "from tensorboardcolab import *\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import Conv1D,MaxPooling1D,  LeakyReLU\n",
        "import keras.backend as K\n",
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHmd0sygHU-R",
        "colab_type": "code",
        "outputId": "3e8f0b4a-2db9-4990-ddcc-6ddb46adf505",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "text_input = Input(shape=(400,), name = \"text_input\")\n",
        "# max_length = 400 ---->max length of sentence\n",
        "\n",
        "e1 = Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=400)(text_input)\n",
        "\n",
        "l1= LSTM(128,activation = \"relu\",dropout=0.5,kernel_regularizer=l2(0.001),kernel_initializer='glorot_normal',return_sequences=True,input_shape=(150,300))(e1)\n",
        "#dout = Dropout(0.5)(l1)\n",
        "f1= Flatten()(l1)\n",
        "\n",
        "rem = Input(shape=(x_tr_rem.shape[1],1), name=\"rem\")\n",
        "rem_conv1 = Conv1D(128, 3,kernel_initializer='glorot_normal')(rem)\n",
        "\n",
        "max_pool =MaxPooling1D(3)(rem_conv1)\n",
        "#rem_conv3 =Conv1D(64, 3, activation='sigmoid')(max_pool)\n",
        "#rem_conv4 =Conv1D(128, 3, activation='sigmoid')(rem_conv3)\n",
        "f2= Flatten()(max_pool)\n",
        "x = keras.layers.concatenate([f1,f2])\n",
        "\n",
        "#x=BatchNormalization()(x)\n",
        "x= Dense(32,kernel_regularizer=l2(0.001),kernel_initializer='glorot_normal')(x)\n",
        "x= Dense(16, activation='relu')(x)\n",
        "output=Dense(2, activation='softmax')(x)\n",
        "model_3 = Model(inputs=[text_input,rem], outputs=output)\n",
        "model_3.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         (None, 400)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "rem (InputLayer)                (None, 102, 1)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 400, 300)     14240100    text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 100, 128)     512         rem[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 400, 128)     219648      embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 33, 128)      0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 51200)        0           lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 4224)         0           max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 55424)        0           flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 32)           1773600     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 16)           528         dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            34          dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 16,234,422\n",
            "Trainable params: 16,234,422\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t7M3f-AHwB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://stackoverflow.com/posts/51734992/revisions\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def auroc(y_true, y_pred):\n",
        "    return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWRz25ZwHyvX",
        "colab_type": "code",
        "outputId": "f6516419-af90-482b-db11-a85fd2d8b265",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "source": [
        "adam = keras.optimizers.Adam(lr=0.001)\n",
        "model_3.compile(optimizer=adam, loss='categorical_crossentropy',metrics=[auroc])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-24-4a25250c5bd7>:5: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hqfNoBtNk0q",
        "colab_type": "code",
        "outputId": "1116dbd5-c57c-4735-80e8-a1f065eda48d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "from keras.callbacks import *\n",
        "from sklearn.metrics import roc_auc_score\n",
        "checkpoint = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
        "#callbacks_list = [checkpoint]\n",
        "batch_size = 512\n",
        "filepath = '/content/drive/My Drive/LSTM Assignment/epochs:{epoch:03d}-val_auc:{val_auroc:.3f}.hdf5'\n",
        "#earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
        "mcp_save = ModelCheckpoint(filepath, save_best_only=True, monitor='val_auc', mode='max')\n",
        "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, verbose=1,min_lr=0.001, mode='min')\n",
        "callbacks=[checkpoint, mcp_save, reduce_lr_loss]\n",
        "\n",
        "history_3= model_3.fit({'text_input': essay_padded_train, 'rem':x_tr_rem_reshape},y_binary_train,\n",
        "          epochs=10, batch_size=512,verbose=1, validation_data=({'text_input': essay_padded_cv, 'rem': x_cv_rem_reshape},y_binary_cv),callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 69918 samples, validate on 17480 samples\n",
            "Epoch 1/10\n",
            "69918/69918 [==============================] - 1266s 18ms/step - loss: 0.5759 - auroc: 0.6585 - val_loss: 0.4355 - val_auroc: 0.7325\n",
            "Epoch 2/10\n",
            "69918/69918 [==============================] - 1251s 18ms/step - loss: 0.4099 - auroc: 0.7357 - val_loss: 0.3943 - val_auroc: 0.7502\n",
            "Epoch 3/10\n",
            "69918/69918 [==============================] - 1256s 18ms/step - loss: 0.3819 - auroc: 0.7613 - val_loss: 0.3805 - val_auroc: 0.7546\n",
            "Epoch 4/10\n",
            "69918/69918 [==============================] - 1246s 18ms/step - loss: 0.3683 - auroc: 0.7813 - val_loss: 0.3802 - val_auroc: 0.7526\n",
            "Epoch 5/10\n",
            "69918/69918 [==============================] - 1251s 18ms/step - loss: 0.3543 - auroc: 0.8018 - val_loss: 0.3821 - val_auroc: 0.7511\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.001.\n",
            "Epoch 00005: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV448VsYIXWk",
        "colab_type": "code",
        "outputId": "596938a2-afea-455e-edfa-3ae3c1b481bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "result = model_3.evaluate({'text_input': essay_padded_test, 'rem':x_test_rem_reshape},\n",
        "          y_binary_test,batch_size=512)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21850/21850 [==============================] - 104s 5ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7Ect_Oeppny",
        "colab_type": "code",
        "outputId": "3a14725a-4e6e-49b4-a58d-da1835621361",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(\"{} of test data {}\". format(model_3.metrics_names[0],result[0]))\n",
        "print(\"{} of test data {}\". format(model_3.metrics_names[1],result[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss of test data 0.38519651322670334\n",
            "auroc of test data 0.7469911987786353\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JfLx6sS-rHV",
        "colab_type": "code",
        "outputId": "dd0e7cf4-3b42-44d5-9871-9d5a8c008ad6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "Z=PrettyTable()\n",
        "Z.field_names=[\"model\",\"test_auc\",\"test_loss\"]\n",
        "Z.add_row([\"model_1\",\"73.82\",\"0.411\"])\n",
        "Z.add_row([\"model_2\",\"75.91\",\"0.445\"])\n",
        "Z.add_row([\"model_3\",\"74.69\",\"0.385\"])\n",
        "\n",
        "print(Z)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+----------+-----------+\n",
            "|  model  | test_auc | test_loss |\n",
            "+---------+----------+-----------+\n",
            "| model_1 |  73.82   |   0.411   |\n",
            "| model_2 |  75.91   |   0.445   |\n",
            "| model_3 |  74.69   |   0.385   |\n",
            "+---------+----------+-----------+\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}